# 데이터 기반 유저 세분화 및 개인화 전략 (User Segmentation & Personalization)

## 목차
1. 개요 및 통합 목적
2. RFM 분석 및 LTV 예측
3. 세그먼트별(Whale/High/Medium/At-risk) 분류 방법
4. 실전 SQL/파이프라인 예시
5. Redis/Kafka/배치(스케줄러) 연동
6. 세그먼트별 추천/보상/미션 설계
7. 실시간/배치 적용법
8. 기업/본사 연계 리텐션 전략
9. 실전 운영 사례 및 체크리스트

---

## 1. 개요 및 통합 목적
Casino-Club F2P의 유저 세분화, 개인화, 리텐션 전략을 실전 중심으로 통합 정리합니다. (RFM, LTV, 세그먼트, 추천, 운영 사례 등)

## 2. RFM 분석 및 LTV 예측
- **RFM(Recency, Frequency, Monetary) 분석 방법론**
  - Recency: 최근 활동일 기준 (예: 마지막 게임 플레이, 콘텐츠 언락, 토큰 획득)
  - Frequency: 최근 30일 내 주요 액션(게임, 미션, 방문 등) 횟수
  - Monetary: 최근 30일 내 실제 결제 또는 토큰 소비/획득 총액

**실전 SQL 예시:**
```sql
-- Recency (일 단위)
SELECT DATEDIFF(day, MAX(action_timestamp), CURRENT_DATE) AS recency
FROM user_actions WHERE user_id = :user_id;

-- Frequency (30일 내 액션 수)
SELECT COUNT(*) AS frequency
FROM user_actions WHERE user_id = :user_id AND action_timestamp >= DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY);

-- Monetary (30일 내 토큰 소비/획득)
SELECT SUM(metadata->>'spent_tokens')::INTEGER AS spent_tokens
FROM user_actions WHERE user_id = :user_id AND action_type = 'SPEND_CYBER_TOKENS' AND action_timestamp >= DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY);
```

**LTV(Lifetime Value) 예측 공식 및 실전 적용법**
- LTV = 평균 결제액 × 평균 재방문 횟수 × 평균 유지 기간
- 예측 파이프라인: 배치 작업(예: APScheduler)으로 주기적 산출, Redis에 캐싱, 실시간 추천/보상에 활용

**파이프라인 예시:**
1. APScheduler로 매일 새벽 RFM/LTV 계산
2. 결과를 user_segments, user_ltv 테이블에 저장
3. Redis에 user:{id}:rfm, user:{id}:ltv 캐싱
4. Kafka로 실시간 세그먼트 변경 이벤트 발행

## 3. 세그먼트별 분류 방법
- **그룹 정의:**
  - Whale: R ≤ 2일, F ≥ 30회, M ≥ 10,000토큰
  - High Engaged: R ≤ 5일, F ≥ 15회, M ≥ 2,000토큰
  - Medium: R ≤ 10일, F ≥ 5회, M ≥ 500토큰
  - At-risk: R > 10일, F < 5회, M < 500토큰

**실전 분류 SQL 예시:**
```sql
SELECT user_id,
  CASE
    WHEN recency <= 2 AND frequency >= 30 AND monetary >= 10000 THEN 'Whale'
    WHEN recency <= 5 AND frequency >= 15 AND monetary >= 2000 THEN 'High Engaged'
    WHEN recency <= 10 AND frequency >= 5 AND monetary >= 500 THEN 'Medium'
    ELSE 'At-risk'
  END AS rfm_group
FROM (
  -- RFM 서브쿼리 (위 SQL 참고)
) rfm_stats;
```

**운영 팁:**
- 세그먼트는 user_segments 테이블에 저장, Redis에 캐싱, Kafka로 변경 이벤트 발행

## 4. 실전 SQL/파이프라인 예시
- **PostgreSQL, Redis, Kafka, APScheduler 활용 예시**

**배치 파이프라인 구조:**
1. APScheduler로 매일 03:00에 RFM/LTV 계산
2. 결과를 user_segments, user_ltv 테이블에 저장
3. Redis에 user:{id}:rfm, user:{id}:ltv, user:{id}:segment 캐싱
4. Kafka로 실시간 세그먼트 변경 이벤트 발행 (예: "segment_changed")

**실시간 파이프라인 구조:**
1. 유저 액션 발생 시 (예: EARN_CYBER_TOKENS)
2. Redis streak, last_action_ts, pending_gems 등 실시간 업데이트
3. Kafka로 이벤트 발행 (예: "action_earned_token")
4. 필요시 Celery로 비동기 후처리

**Redis 활용 예시:**
```
user:{id}:streak_count
user:{id}:last_action_ts
user:{id}:pending_gems
battlepass:{user_id}:xp
```

**Kafka 활용 예시:**
- 실시간 세그먼트 변경, 리텐션 이벤트, 추천/보상 트리거

## 5. 세그먼트별 추천/보상/미션 설계
- **그룹별 맞춤 설계:**
  - Whale: 고가 패키지, 한정판, VIP 미션, 대형 보상, 실시간 랭킹/리더보드
  - High Engaged: 연속 출석 보상, 미션형 보상, 한정 이벤트, 커뮤니티 랭킹
  - Medium: 소액 패키지, 성장형 미션, 리텐션 푸시, 무료 가챠/슬롯
  - At-risk: 복귀 보상, 무료 토큰, 심리적 동기 부여(성공 경험, 소셜 증거)

**실전 적용 사례:**
- Whale: 1:1 VIP 매니저, 전용 한정판, 대형 토너먼트 초대
- High Engaged: 주간 미션, 커뮤니티 랭킹전, 한정판 뱃지
- Medium: 성장형 미션, 무료 가챠, 소액 결제 유도
- At-risk: 복귀 유도 푸시, 무료 토큰, "오늘만 한정" 미션

**운영 팁:**
- 추천/보상/미션은 실시간 세그먼트에 따라 동적으로 노출
- Redis/Kafka로 실시간 트리거, APScheduler로 배치 보상 동시 운영

## 6. 실시간/배치 적용법
- APScheduler, Celery, Redis 캐시 활용
- 실시간/배치 동시 적용 전략

## 7. 기업/본사 연계 리텐션 전략
- 본사/파트너 연계 리텐션/수익화 전략
- 실전 운영 사례

## 8. 실전 운영 체크리스트
- 데이터 파이프라인 점검, 장애 대응, 운영 자동화 팁

---

> 기존: 02_data_personalization_en.md, 05_corporate_retention_en.md, 유저심리_기반_수익개선전략.md 통합
> 실제 코드/운영/UX 예시, 체크리스트, 실전 적용법, 개선 이력 포함. (내용 병합은 2차 단계에서 진행)
